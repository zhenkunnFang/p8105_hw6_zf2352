p8105_hw6_zf2352
================
Zhenkun Fang
2024-12-02

# Problem 1

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

``` r
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}


boot_straps = 
  tibble(strap_number = 1:5000) |> 
  mutate(
    strap_sample = map(strap_number, \(i) boot_sample(df = weather_df))
  )

boot_straps
```

    ## # A tibble: 5,000 × 2
    ##    strap_number strap_sample      
    ##           <int> <list>            
    ##  1            1 <tibble [365 × 6]>
    ##  2            2 <tibble [365 × 6]>
    ##  3            3 <tibble [365 × 6]>
    ##  4            4 <tibble [365 × 6]>
    ##  5            5 <tibble [365 × 6]>
    ##  6            6 <tibble [365 × 6]>
    ##  7            7 <tibble [365 × 6]>
    ##  8            8 <tibble [365 × 6]>
    ##  9            9 <tibble [365 × 6]>
    ## 10           10 <tibble [365 × 6]>
    ## # ℹ 4,990 more rows

``` r
bootstrap_results1 = 
  boot_straps |> 
  mutate(
    models = map(strap_sample, \(df) lm(tmax ~ tmin, data = df) ),
    results = map(models, broom::glance)) |> 
  select(-strap_sample, -models) |> 
  unnest(results) 


bootstrap_results1 |> 
  summarize(
    rsquare_lower = quantile(r.squared, 0.025), 
    rsquare_upper = quantile(r.squared, 0.975)) %>% 
    knitr::kable(digits = 3)
```

| rsquare_lower | rsquare_upper |
|--------------:|--------------:|
|         0.894 |         0.928 |

``` r
bootstrap_results2 = 
  boot_straps |> 
  mutate(
    models = map(strap_sample, \(df) lm(tmax ~ tmin, data = df) ),
    results = map(models, broom::tidy)) |> 
  select(-strap_sample, -models) |> 
  unnest(results) 

bootstrap_results2 = bootstrap_results2 |> 
  group_by(strap_number) |> 
  summarize(log_beta = log(
      estimate[term == "(Intercept)"] * estimate[term == "tmin"]
    )
              )
  
bootstrap_results2 %>% 
  summarize(
    log_beta_lower = quantile(log_beta, 0.025), 
    log_beta_upper = quantile(log_beta, 0.975)
  ) %>% 
    knitr::kable(digits = 3)
```

| log_beta_lower | log_beta_upper |
|---------------:|---------------:|
|          1.965 |           2.06 |

``` r
ggplot(bootstrap_results1, aes(x = r.squared)) +
  geom_histogram(bins = 30, fill = "green", alpha = 0.7) +
  labs(
    title = "Distribution of Bootstrap Estimates for R-squared",
    x = "R-squared",
    y = "Frequency"
  ) +
  theme_minimal()
```

![](p8105_hw6_zf2352_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

The distribution appears symmetric and approximately bell-shaped,
resembling a normal distribution.This suggests that the variability of
$R^2$ values is consistent across the bootstrap samples. The
distribution is centered around $R^2$ values between 0.90 and 0.92,
indicating that the model consistently explains about 90-92% of the
variance in the response variable across resamples.

``` r
ggplot(bootstrap_results2, aes(x = log_beta)) +
  geom_histogram(bins = 30, fill = "blue", alpha = 0.7) +
  labs(
    title = "Distribution of Bootstrap Estimates for log_beta",
    x = "log_beta",
    y = "Frequency"
  ) +
  theme_minimal()
```

![](p8105_hw6_zf2352_files/figure-gfm/unnamed-chunk-6-1.png)<!-- -->

The distribution is symmetric and bell-shaped, closely resembling a
normal distribution. This indicates that the variability in `log_beta`
estimates across bootstrap samples is relatively consistent and
unbiased. The expected log-transformed product of the coefficients is
approximately 2.

# Problem 2

``` r
homicide_data <- read_csv("homicide-data.csv")
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
homicide_data = homicide_data %>%
  mutate(city_state = paste(city, state, sep = ", ")) %>% 
  mutate(is_solved = ifelse(disposition == "Closed by arrest", 1, 0)) %>% 
  filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ", 
                        "Kansas City, MO", "Tulsa, AL"))
  ) %>%
  filter(victim_race %in% c("White", "Black")) %>%
  mutate(victim_age = as.numeric(victim_age)) %>%
  filter(!is.na(victim_age))
```

``` r
baltimore_data = homicide_data %>%
  filter(city_state == "Baltimore, MD")

logistic_model <- glm(
  is_solved ~ victim_age + victim_sex + victim_race,
  data = baltimore_data,
  family = binomial(link = "logit")  
)

model_summary <- broom::tidy(
  logistic_model, 
  conf.int = TRUE,     
  conf.level = 0.95    
)

odds_ratio <- model_summary %>%
  filter(term == "victim_sexMale") %>%
  mutate(
    odds_ratio = exp(estimate),  
    lower_ci = exp(conf.low),   
    upper_ci = exp(conf.high)    
  ) 

odds_ratio %>% 
  select(odds_ratio:upper_ci) %>% 
  knitr::kable(digits = 3)
```

| odds_ratio | lower_ci | upper_ci |
|-----------:|---------:|---------:|
|      0.426 |    0.324 |    0.558 |

``` r
city_or_results <- homicide_data %>%
  group_by(city_state) %>%  
  nest() %>%  
  mutate(
    model = map(data, ~ glm(is_solved ~ victim_sex + victim_age + victim_race,
                            data = .x, family = binomial(link = "logit"))), 
    tidy_model = purrr::map(model, ~ broom::tidy(.x, conf.int = TRUE, 
                                          conf.level = 0.95)) 
  ) %>%
  unnest(tidy_model) %>%  
  filter(term == "victim_sexMale") %>%  
  mutate(
    odds_ratio = exp(estimate),  
    lower_ci = exp(conf.low),    
    upper_ci = exp(conf.high)    
  ) %>%
  select(city_state, odds_ratio, lower_ci, upper_ci, p.value)  

print(city_or_results)
```

    ## # A tibble: 47 × 5
    ## # Groups:   city_state [47]
    ##    city_state      odds_ratio lower_ci upper_ci  p.value
    ##    <chr>                <dbl>    <dbl>    <dbl>    <dbl>
    ##  1 Albuquerque, NM      1.77     0.825    3.76  1.39e- 1
    ##  2 Atlanta, GA          1.00     0.680    1.46  1.00e+ 0
    ##  3 Baltimore, MD        0.426    0.324    0.558 6.26e-10
    ##  4 Baton Rouge, LA      0.381    0.204    0.684 1.65e- 3
    ##  5 Birmingham, AL       0.870    0.571    1.31  5.11e- 1
    ##  6 Boston, MA           0.674    0.353    1.28  2.26e- 1
    ##  7 Buffalo, NY          0.521    0.288    0.936 2.90e- 2
    ##  8 Charlotte, NC        0.884    0.551    1.39  6.00e- 1
    ##  9 Chicago, IL          0.410    0.336    0.501 1.86e-18
    ## 10 Cincinnati, OH       0.400    0.231    0.667 6.49e- 4
    ## # ℹ 37 more rows

``` r
ggplot(city_or_results, aes(x = odds_ratio, 
                            y = reorder(city_state, odds_ratio))) +
  geom_point(color = "blue", size = 3) + 
  geom_errorbarh(aes(xmin = lower_ci, xmax = upper_ci), height = 0.2, color = "black") +  
  labs(
    title = "Estimated Odds Ratios (ORs) and Confidence Intervals (CIs) by City",
    x = "Odds Ratio (log scale)",
    y = "City"
  ) +
  scale_x_log10() + 
  theme_minimal()
```

![](p8105_hw6_zf2352_files/figure-gfm/unnamed-chunk-11-1.png)<!-- -->

The odds ratios range from 0.28 to 2.1 approximately. Cities with odds
ratios less than 1 (e.g., Albuquerque, NM) indicate that male victims
are less likely to have their homicides solved compared to female
victims. Cities with odds ratios greater than 1 (e.g., New York, NY)
indicate that male victims are more likely to have their homicides
solved compared to female victims.

A few cities have extreme odds ratios (e.g., New York, NY), suggesting
unique dynamics in homicide resolution for male vs. female victims.
